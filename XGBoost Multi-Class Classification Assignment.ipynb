{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Imports***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Load Dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('sf-crime/train.csv')\n",
    "test_set = pd.read_csv('sf-crime/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Changing Dates Column into Separate Columns***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = []\n",
    "months = []\n",
    "days = []\n",
    "times = []\n",
    "\n",
    "# Separate dates in terms of year, month, day and time\n",
    "def change_dates(date):\n",
    "    # split date\n",
    "    parts = date.split('-')\n",
    "    years.append(int(parts[0]))\n",
    "    months.append(int(parts[1]))\n",
    "    # second split to split day and time apart\n",
    "    parts = parts[2].split(' ')\n",
    "    days.append(int(parts[0]))\n",
    "    # removing : from time\n",
    "    time = parts[1].replace(':', '')\n",
    "    times.append(int(time))\n",
    "    \n",
    "    \n",
    "\n",
    "train_set['Dates'].apply(change_dates)\n",
    "\n",
    "# turn into dataframes\n",
    "years = pd.DataFrame(years, columns=['Year'])\n",
    "months =  pd.DataFrame(months, columns=['Month'])\n",
    "days = pd.DataFrame(days, columns=['Day'])\n",
    "times = pd.DataFrame(times, columns=['Time'])\n",
    "\n",
    "# readd to original dataframe\n",
    "train_set = pd.concat([train_set, years, months, days, times], axis=1)\n",
    "train_set.drop(['Dates'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = []\n",
    "months = []\n",
    "days = []\n",
    "times = []\n",
    "\n",
    "# Separate dates in terms of year, month, day and time\n",
    "def change_dates(date):\n",
    "    # split date\n",
    "    parts = date.split('-')\n",
    "    years.append(int(parts[0]))\n",
    "    months.append(int(parts[1]))\n",
    "    # second split to split day and time apart\n",
    "    parts = parts[2].split(' ')\n",
    "    days.append(int(parts[0]))\n",
    "    # removing : from time\n",
    "    time = parts[1].replace(':', '')\n",
    "    times.append(int(time))\n",
    "    \n",
    "    \n",
    "\n",
    "test_set['Dates'].apply(change_dates)\n",
    "\n",
    "# turn into dataframes\n",
    "years = pd.DataFrame(years, columns=['Year'])\n",
    "months =  pd.DataFrame(months, columns=['Month'])\n",
    "days = pd.DataFrame(days, columns=['Day'])\n",
    "times = pd.DataFrame(times, columns=['Time'])\n",
    "\n",
    "# readd to original dataframe\n",
    "test_set = pd.concat([test_set, years, months, days, times], axis=1)\n",
    "test_set.drop(['Dates'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Encode Day of Week***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_encoder = OrdinalEncoder()\n",
    "\n",
    "# fit transforming using encoder\n",
    "train_set['DayOfWeek'] = day_encoder.fit_transform(train_set[['DayOfWeek']])\n",
    "\n",
    "# transforming using same encoder\n",
    "test_set['DayOfWeek'] = day_encoder.transform(test_set[['DayOfWeek']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Encode Category***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_encoder = OrdinalEncoder()\n",
    "\n",
    "# fit transforming using encoder\n",
    "train_set['Category'] = category_encoder.fit_transform(train_set[['Category']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Determin X and Y data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping only relavant columns\n",
    "columns = ['Year', 'Month', 'Day', 'Time', 'DayOfWeek', 'X', 'Y']\n",
    "\n",
    "X_train = train_set[columns]\n",
    "Y_train = train_set['Category']\n",
    "X_test = test_set[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Train Model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=Y_train)\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "\n",
    "# parameters for XGBoost\n",
    "params = {\n",
    "        'objective' : 'multi:softmax',\n",
    "        'num_class' : 39,\n",
    "        'max_depth' : 3,\n",
    "        'eta' : 0.1 }\n",
    "\n",
    "# train model\n",
    "num_rounds = 100\n",
    "model = xgb.train(params, dtrain, num_rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Predict on Test Data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = prediction.reshape(-1, 1)\n",
    "\n",
    "# decode prediction\n",
    "decode_prediction = category_encoder.inverse_transform(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn into dataframe\n",
    "predictions = pd.DataFrame(decode_prediction)\n",
    "\n",
    "# create dummies\n",
    "predictions = pd.get_dummies(predictions, prefix='', prefix_sep='', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding missing categories\n",
    "\n",
    "category = train_set['Category'].to_numpy().reshape(-1, 1)\n",
    "\n",
    "# get separate decoded categories\n",
    "decoded_categories = category_encoder.inverse_transform(category)\n",
    "decoded_categories = pd.DataFrame(decoded_categories)\n",
    "decoded_categories = pd.get_dummies(decoded_categories, prefix='', prefix_sep='')\n",
    "\n",
    "# getting missing categories\n",
    "missing_categories = list(set(decoded_categories.columns) - set(predictions.columns))\n",
    "\n",
    "# turning missing cateegories into dataframe\n",
    "missing_categories = pd.DataFrame(0, index=predictions.index, columns=missing_categories)\n",
    "\n",
    "# combining dataframes\n",
    "predictions = pd.concat([predictions, missing_categories], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add ID column\n",
    "predictions['Id'] = test_set['Id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Create Submission***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
